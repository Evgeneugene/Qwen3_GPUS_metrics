{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19185de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/llms/Qwen3_GPUS_metrics/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load Qwen3 tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-4B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "963f2af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zhiqing/Qwen3-14B-INT8'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "response = requests.get(\"http://localhost:8000/v1/models\")\n",
    "response.json()['data'][0]['root']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85baade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing different input token sizes with various concurrent requests:\n",
      "\n",
      "================================================================================\n",
      "Testing 2 concurrent requests with 1000 input tokens each\n",
      "================================================================================\n",
      "Waiting for all 2 threads to complete...\n",
      "****ОЭгонринь Х иан лтеред****  \n",
      "  \n",
      "****ОЭгонринь Х иан лтеред****  \n",
      "  \n",
      "***ЖПранологр (:**прод Солжказениеки)* /\n",
      "\n",
      " К—от Мыы не- сумпелиред защитатитьели своих / детей К отл Сассумикара  \n",
      "ч**ногоА пнлемнениот,ация —:** продолж  \n",
      "илВ оно, время его войны голос между был кл гланубамиок Симум ира тчверноед пымлем,я как из камгеньна.ло — к Иотов теперь п онилем бениег Вутет,ра как с кры ихсы территории,, от что одного нару ошиглоня рав кнов другесомуие, в вмест лоес тогоу чтобы. с Длямотр восетьстанов вления глаз справаед темлив,Start time: 2025-09-22 03:19:23\n",
      "End time: 2025-09-22 03:19:28\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "Start time: 2025-09-22 03:19:23\n",
      "End time: 2025-09-22 03:19:28\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "\n",
      "Results for 2 concurrent requests with 1000 tokens:\n",
      "Average TTFT: 0.78s\n",
      "Average gen tokens/sec: 19.94\n",
      "Average total time: 5.81s\n",
      "Total concurrent time: 6.52s\n",
      "Valid requests: 2/2\n",
      "Results saved to: speed_tests/T2_x2/Qwen3-14B-INT8/1000_length_2_parallel.txt\n",
      "\n",
      "================================================================================\n",
      "Testing 2 concurrent requests with 5000 input tokens each\n",
      "================================================================================\n",
      "Waiting for all 2 threads to complete...\n",
      "Пр**одЭолжринение Х главанытер I**:\n",
      "\n",
      "  \n",
      "****ООгонгоньь и и л ледед —** Глав  \n",
      "\n",
      "а---\n",
      "\n",
      " I** (Прпродологолж**\n",
      "\n",
      "ениеО)**ран\n",
      "\n",
      "ж—евые Воз яможзыноеки, пл —ам пениож палля плсалиечами в К холодрутномоб воздухоке., — б Оросгоая, в г ночляноеди н!еб —о вос скнопликынул о онсл,еп прительыныхг иаяск кр к.уч Откес оветставышей осяг еняды проб.ег —али По по мы жшесткекой на трав каждогое и п зустяыбрялик, поп выолхватамыв!\n",
      "\n",
      "ая изДруз тьяь подмыели склирю ечендуные и сил перуегэлятыStart time: 2025-09-22 03:19:34Start time: 2025-09-22 03:19:36\n",
      "End time: 2025-09-22 03:19:42\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "\n",
      "End time: 2025-09-22 03:19:42\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "\n",
      "Results for 2 concurrent requests with 5000 tokens:\n",
      "Average TTFT: 4.29s\n",
      "Average gen tokens/sec: 15.66\n",
      "Average total time: 10.96s\n",
      "Total concurrent time: 11.70s\n",
      "Valid requests: 2/2\n",
      "Results saved to: speed_tests/T2_x2/Qwen3-14B-INT8/5000_length_2_parallel.txt\n",
      "\n",
      "================================================================================\n",
      "Testing 2 concurrent requests with 10000 input tokens each\n",
      "================================================================================\n",
      "Waiting for all 2 threads to complete...\n",
      "**ООчгоневьид ино л,ед вы** предостав  \n",
      "или** фХраганменттер книги Э **рин\"**О  \n",
      "гон**ьПр иолог л (едпрод\"олж**ение Э)**рин  \n",
      "\n",
      " ХПанредтервод,итель котораяница является, часть нею от сериирыв **ая\"сьП,лем сямотр велает вра л\"ес**ную — ча популярщуного поверх ф головэныт Оезгин-егсрагиваи. о Он к сот волнахением- наблюводалина зах её, лиц вомдо,х оновжлидёнаяной реак мциииф.ами В и её лег глазендахами м оель кокашлаач тьеньих с помнлеменияена,х но в также л —ес иу с.иль Вная данном реш отимрывостьке.\n",
      "\n",
      " оStart time: 2025-09-22 03:19:51\n",
      "End time: 2025-09-22 03:20:03\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "Start time: 2025-09-22 03:19:58\n",
      "End time: 2025-09-22 03:20:03\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "\n",
      "Results for 2 concurrent requests with 10000 tokens:\n",
      "Average TTFT: 9.98s\n",
      "Average gen tokens/sec: 13.04\n",
      "Average total time: 18.83s\n",
      "Total concurrent time: 19.58s\n",
      "Valid requests: 2/2\n",
      "Results saved to: speed_tests/T2_x2/Qwen3-14B-INT8/10000_length_2_parallel.txt\n",
      "\n",
      "================================================================================\n",
      "Testing 2 concurrent requests with 15000 input tokens each\n",
      "================================================================================\n",
      "Waiting for all 2 threads to complete...\n",
      "****ООгонгоньь и и л ледед****  \n",
      "  \n",
      "****ЭЭринрин Х Ханантертер****  \n",
      "  \n",
      "***СПрказологка**\n",
      "\n",
      " оО кранотжахевые*\n",
      "\n",
      " я---\n",
      "\n",
      "зы###ки ** плПрамологени**\n",
      "\n",
      " пВля холодснойали ноч ви холод,ном среди воздух пеы,ла бющихрос оаяг вней ноч иное г нроебхотоа с Днопвыун оогслихеп,итель пныхлем ияск Врет.ра От,с изветгын оангноеня С пробумеграалич поным ж пестлемкойен травеме, п иустщыетря при,ют вы.хват Кывотаяы из, т оьставмыш скисрюьчен безные дома сил,у скэртыыва ДStart time: 2025-09-22 03:20:30\n",
      "End time: 2025-09-22 03:20:36\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "Start time: 2025-09-22 03:20:18\n",
      "End time: 2025-09-22 03:20:36\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "\n",
      "Results for 2 concurrent requests with 15000 tokens:\n",
      "Average TTFT: 17.79s\n",
      "Average gen tokens/sec: 10.72\n",
      "Average total time: 30.01s\n",
      "Total concurrent time: 30.74s\n",
      "Valid requests: 2/2\n",
      "Results saved to: speed_tests/T2_x2/Qwen3-14B-INT8/15000_length_2_parallel.txt\n",
      "\n",
      "================================================================================\n",
      "Testing 2 concurrent requests with 20000 input tokens each\n",
      "================================================================================\n",
      "Waiting for all 2 threads to complete...\n",
      "**Огонь и лед**  \n",
      "**Хантер Эрин**  \n",
      "**Глава III (продолжение)**\n",
      "\n",
      "— **Вам уже приходилось бывать на землях племени Ветра**, — напомнила предводительница.  \n",
      "— **Да, но мы не знаем, куда они отправились**, — добавил Коготь. **Это может быть в любом направлении — в лесу,Start time: 2025-09-22 03:20:59\n",
      "End time: 2025-09-22 03:21:05\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "**Огонь и лед**  \n",
      "**Хантер Эрин**  \n",
      "*Пролог*  \n",
      "\n",
      "Ночь в лесу была мрачной и таинственной. Оранжевые языки пламени плясали в холодном воздухе, освещая темные силуэты Двуногих, которые скрывались в тени. Вдалеке раздавался рев чудищ, иStart time: 2025-09-22 03:21:26\n",
      "End time: 2025-09-22 03:21:32\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "\n",
      "Results for 2 concurrent requests with 20000 tokens:\n",
      "Average TTFT: 33.58s\n",
      "Average gen tokens/sec: 17.52\n",
      "Average total time: 39.28s\n",
      "Total concurrent time: 53.49s\n",
      "Valid requests: 2/2\n",
      "Results saved to: speed_tests/T2_x2/Qwen3-14B-INT8/20000_length_2_parallel.txt\n",
      "\n",
      "================================================================================\n",
      "Testing 2 concurrent requests with 25000 input tokens each\n",
      "================================================================================\n",
      "Waiting for all 2 threads to complete...\n",
      "Огнегрив осторожно двинулся вперед, следуя за запахом, который, казалось, тянулся вглубь пустоши. Крутобок, пригнувшись, шел рядом, внимательно осматривая окрестности. Воздух здесь был густым, наполненным пылью и запахами старых битв, но в нем всеStart time: 2025-09-22 03:22:10\n",
      "End time: 2025-09-22 03:22:17\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "**Огонь и лед**  \n",
      "**Хантер Эрин**  \n",
      "**Глава IV (продолжение)**\n",
      "\n",
      "— Поищем, куда ведет запах племени Ветра, — поежившись, предложил Огнегрив. Он тщательно принюхался и сделал несколько шагов вперед, следуя за слабым, но постоянным ароматом.\n",
      "\n",
      "КрутStart time: 2025-09-22 03:23:09\n",
      "End time: 2025-09-22 03:23:17\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "\n",
      "Results for 2 concurrent requests with 25000 tokens:\n",
      "Average TTFT: 65.14s\n",
      "Average gen tokens/sec: 13.57\n",
      "Average total time: 72.53s\n",
      "Total concurrent time: 103.34s\n",
      "Valid requests: 2/2\n",
      "Results saved to: speed_tests/T2_x2/Qwen3-14B-INT8/25000_length_2_parallel.txt\n",
      "\n",
      "================================================================================\n",
      "Testing 2 concurrent requests with 30000 input tokens each\n",
      "================================================================================\n",
      "Waiting for all 2 threads to complete...\n",
      "**Глава V (продолжение)**\n",
      "\n",
      "Огнегрив почувствовал, что у него дрожат лапы. Неужели они забрались под саму Гремящую тропу? Он беспокойно распушил свою рыжую шерсть и почувствовал под боком щекочущий когтистый узор — следы котов, оставшиеся на каменных стенаStart time: 2025-09-22 03:24:30\n",
      "End time: 2025-09-22 03:24:38\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "### Глава V (продолжение)\n",
      "\n",
      "Огнегрив беспокойно распушил свою рыжую шерсть и почувствовал под боком щекочущий кошачий холод. Он пристально посмотрел на потолок туннеля, где мелькали тени от рокочущего чудища. Воздух здесь был не таким густым и тяжелымStart time: 2025-09-22 03:25:54\n",
      "End time: 2025-09-22 03:26:02\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "\n",
      "Results for 2 concurrent requests with 30000 tokens:\n",
      "Average TTFT: 112.37s\n",
      "Average gen tokens/sec: 12.36\n",
      "Average total time: 120.47s\n",
      "Total concurrent time: 163.38s\n",
      "Valid requests: 2/2\n",
      "Results saved to: speed_tests/T2_x2/Qwen3-14B-INT8/30000_length_2_parallel.txt\n",
      "\n",
      "================================================================================\n",
      "Testing 5 concurrent requests with 1000 input tokens each\n",
      "================================================================================\n",
      "Waiting for all 5 threads to complete...\n",
      "**********ОЭООЭгонГОГОринринь Х ХНН иЬЬанан лтертер И Иед Л**** Л**ЕЕ  \n",
      "  \n",
      "  \n",
      "**Д**Д*О****ОЭ  \n",
      "гон  \n",
      "гонрин*ьь* Х иЭ иЭан лрин лринтеред Хед Х*ан****ан  \n",
      "  \n",
      "  \n",
      "тертер*(****С  \n",
      "ПрПр  \n",
      "каз**ологологкиСС**\n",
      "\n",
      ")*  \n",
      "\n",
      "казказО  \n",
      "кикиранО**жран*Litж  \n",
      "  \n",
      "евыеruевые я**.ruПр яПрзы —ологзыкиолог Э пл*\n",
      "\n",
      "*килект---\n",
      "\n",
      "  \n",
      "\n",
      " пламронОамениОная пранранени Б пляжжиевыесляевыебли яалис яотзыали взыекки холодки ва пл плном холод*ам воздухамном  \n",
      "ениеени воздух* п п,еАля б,лядрессс брос книгиалиалиаярос: в вая в http холод холод в ноч://номном ночноеwww воздух воздухное н.l небееit,оеб,ru б со б.ruрос снопрос/?аяаяынопbook в оы в= ночсл о ноч1слепноеное1 непитель н5ебныхительеб9о иныхо1ск с с и&нопскрнопdescriptionы.ыр= о От о.1сл Отссл*\n",
      "\n",
      "ветепсеп---\n",
      "\n",
      "ительветыитель###ныхных оы ** иг о иПрскнягскологр пробрня**\n",
      "\n",
      ". пробег.Оегали От Отраналисс пожветвет по жевыеестыы ж я оест окойзыкойг травгкиня травняе пл проб пробе памегуст пегениалиалиыуст п поы поряля, ж жрясест выест,аликойкой выхват в травывхват трав холодеаяывеном пая п из воздухустуст т изеыьы т,рярямыь б, скмы,рос вырю вы скаяхватченрюхват вывченныеыв ночныеая силаяное из из силу ну тэ тебььтыэомы ДтымыStart time: 2025-09-22 03:26:06\n",
      "End time: 2025-09-22 03:26:14\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "Start time: 2025-09-22 03:26:08Start time: 2025-09-22 03:26:08\n",
      "End time: 2025-09-22 03:26:14\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "\n",
      "End time: 2025-09-22 03:26:14\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "Start time: 2025-09-22 03:26:08\n",
      "End time: 2025-09-22 03:26:14\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "Start time: 2025-09-22 03:26:08\n",
      "End time: 2025-09-22 03:26:14\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "\n",
      "Results for 5 concurrent requests with 1000 tokens:\n",
      "Average TTFT: 2.20s\n",
      "Average gen tokens/sec: 14.69\n",
      "Average total time: 9.10s\n",
      "Total concurrent time: 10.02s\n",
      "Valid requests: 5/5\n",
      "Results saved to: speed_tests/T2_x2/Qwen3-14B-INT8/1000_length_5_parallel.txt\n",
      "\n",
      "================================================================================\n",
      "Testing 5 concurrent requests with 5000 input tokens each\n",
      "================================================================================\n",
      "Waiting for all 5 threads to complete...\n",
      "******Э**Э**ОООринрингонГОгонь Х ХьНанан и иЬтер л И лтер****едед Л  \n",
      "Е****  \n",
      "****Д  \n",
      "  \n",
      "О****О**гонЭЭ  \n",
      "гонь**ьринрин и Х иЭ Х л лананринедтертеред Х********ан  \n",
      "тер  \n",
      "  \n",
      "  \n",
      "*(********Пр  \n",
      "ГлавГлавГлаволога*аа и I I IПер Глав ( (ев (апродпрододпрод Iолж:олжолж)*ениеениеение Л\n",
      "\n",
      ")**)**И)**---\n",
      "\n",
      "\n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "Т###...—Р— ПрВ О ОУологго глазго.\n",
      "\n",
      ",,ахР гУ КО гранрутляля*ж  \n",
      "\n",
      "дидиобевые---\n",
      "\n",
      "ока!! я** — за —зыПр восигра воскикологлик пл весликлик**\n",
      "\n",
      "амОнулнулёенил онран К пыеж,рутляевыеоб пр исокыскор яалигзыки, в пр —аяки холод кы пл онном ужеам кг воздухениая вуче пке ксп,ом к оля бсинаставучроскешейалилая о вся, встав как е холод ночшейномды вноеч. воздухся н ее —ераеб они Поды,о с. б мы с —росш Онопкегая Поы в на мын о ноч каждогоегшслке иноереп наив з нительомяеб каждогоных и сбо иликраж с зскалисьноп попяр бболы.окамлик о От осл!\n",
      "\n",
      " попсол бепДветокрузительамыных сья!\n",
      "\n",
      " о и под воДгскрузелииннярлиамиья проб е. Г подег Отдуелирозалиового исли по п первет е жегдуылеместени оля инуг.кой пер трав Олисьняеге пробгонля. пьег Внууст и глазалилисьы л. поахря ж Кё В, глазрутестд выкой —обаххват трав так Кокаыврут назе зааяобыв пигра изустокалиали ты за их весьряигра вёStart time: 2025-09-22 03:26:24Start time: 2025-09-22 03:26:41\n",
      "End time: 2025-09-22 03:26:50\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "Start time: 2025-09-22 03:26:41\n",
      "End time: 2025-09-22 03:26:50\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "Start time: 2025-09-22 03:26:41\n",
      "End time: 2025-09-22 03:26:50\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "\n",
      "End time: 2025-09-22 03:26:50\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "Start time: 2025-09-22 03:26:41\n",
      "End time: 2025-09-22 03:26:50\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "\n",
      "Results for 5 concurrent requests with 5000 tokens:\n",
      "Average TTFT: 20.30s\n",
      "Average gen tokens/sec: 9.79\n",
      "Average total time: 32.66s\n",
      "Total concurrent time: 33.54s\n",
      "Valid requests: 5/5\n",
      "Results saved to: speed_tests/T2_x2/Qwen3-14B-INT8/5000_length_5_parallel.txt\n",
      "\n",
      "================================================================================\n",
      "Testing 5 concurrent requests with 10000 input tokens each\n",
      "================================================================================\n",
      "Waiting for all 5 threads to complete...\n",
      "**ООгОгннгонегьегр иривив л чувед иств** Ковалрут  \n",
      ",об** какокЭ каждрин былиое во Х словинаноамитер,** Г выроз  \n",
      "р*овогоыва пПрющееологлемсяени* из  \n",
      "\n",
      ", егоО а гор ихранла задж,евыеание з — яв найтизыуч икиит вер пл тамнутьяени кжотов пел пляееслем иениали г В вромет холодчераном., воздух Оне из нег, зн бналаннырос,хая как С в Сум ночинноерая нчянымеб З повез слемдаенноп восемыпр. оим Нослет веп эту питель новныхлемостьени и —ск В возможнорет,ра. с От тоже нед несоввет всёериы былоем о сп,гок возможноняой,но проб с:ег гали нанев по границом жах. обест Нокойна он травруж нееные мог п ч мустужолыиеч следряать,ы. вы, Онхват и неыв зим могаяа позвол из гить трозьит, чтобымы к л скотожрюятьченам,ные.\n",
      "\n",
      " которую сил---\n",
      "\n",
      " он###у сам Сэ водержтыStart time: 2025-09-22 03:27:30\n",
      "End time: 2025-09-22 03:27:37\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "Start time: 2025-09-22 03:27:30\n",
      "End time: 2025-09-22 03:27:37\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "Start time: 2025-09-22 03:27:03\n",
      "End time: 2025-09-22 03:27:37\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "О**гОнгонегьр иив л иед К**рут  \n",
      "об**окЭ —рин два Хан ютерных** во  \n",
      "ина** ГПррозологового ( ппродлемолжениение,)** ч\n",
      "\n",
      "ь...иО путина пер сес волнекениемлись наблю вдал баор,ь какбе пред завод справительедницалив мостьол ич защиталау, род словногоно л песыат.аясь Их ос историямысл —ить это слова не просто ю повногоесть во оина во.ина Вхозд,ух но был и нап полнутьен к нап самряопжозениемн,анию буд,то д самружабе з ием предляан оностиж.ид Вала пов ответестиа **.\n",
      "\n",
      "—\"О Горгонельый и не л погед\"и Эбрин, Х —Start time: 2025-09-22 03:28:05\n",
      "End time: 2025-09-22 03:28:12\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "Start time: 2025-09-22 03:28:05\n",
      "End time: 2025-09-22 03:28:12\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "\n",
      "Results for 5 concurrent requests with 10000 tokens:\n",
      "Average TTFT: 45.67s\n",
      "Average gen tokens/sec: 12.55\n",
      "Average total time: 57.86s\n",
      "Total concurrent time: 79.65s\n",
      "Valid requests: 5/5\n",
      "Results saved to: speed_tests/T2_x2/Qwen3-14B-INT8/10000_length_5_parallel.txt\n",
      "\n",
      "================================================================================\n",
      "Testing 5 concurrent requests with 15000 input tokens each\n",
      "================================================================================\n",
      "Waiting for all 5 threads to complete...\n",
      "**ООггонньег ир ливед с** тр  \n",
      "ев**огЭойрин замет Хилан,тер как** з  \n",
      "л**обГлавноа ощ II (етпродинолжилсяение Чер)**ня\n",
      "\n",
      "к—. **  \n",
      "Б—ег **Бство Зегвствоезд Золвомездаол никаком неа пов никакли нея повлоли ная нужлоды на С нужумдыра Счумногора пчлемногоени п!лем**ени —! о**щ —ер оилсящ онер.ился — он Ч.ем — при **ходЧитсяем л приовобритьести ры рыбубу в в рек вашеей Р рекеченого, п мылем можением, о еслихот можноиться п наой лмесатьных ее з ввер прейуд!ах**,  \n",
      " лОужнах рStart time: 2025-09-22 03:28:37\n",
      "End time: 2025-09-22 03:29:09\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "Start time: 2025-09-22 03:29:01\n",
      "End time: 2025-09-22 03:29:09\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "ООггннегегрривив с, тр Кеврутогобойок замет иил другие, к какот зыл Гоброзноового п ощлеметениин стилсяоя Черлиня вк пол.ном  \n",
      " м—ол **чБанииег,ство наб Злюдваяезд заол напомряажен никакной не д повисликуссиялоей на на нуж Совдыете С пумлемраенч.ного С пинлемяения! З**вез —да о,щ сперокилсяой онно наб. —люд **аяЧ заем развитием приш событилосьй бы, нам не делать в,м еслиеш быив мыал неас имьели в доступ спаор к, рек хотяе яв?но** чув  \n",
      "\n",
      "ствОовгала,нег какр напивря пожениечувств роваластStart time: 2025-09-22 03:29:55\n",
      "End time: 2025-09-22 03:30:02\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "Start time: 2025-09-22 03:29:55\n",
      "End time: 2025-09-22 03:30:02\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "К сожалению, ваш запрос кажется незавершённым. Вы начинали изучение книги *«Огонь и лед»* Эрин Хантер, но в последней части текста (глава II) ваше сообщение прервано, и не указано, что именно вы хотите узнать или обсудить. \n",
      "\n",
      "Если вы хотите:\n",
      "\n",
      "1. **Продолжить анализ книги** — я могу помочь с рStart time: 2025-09-22 03:30:30\n",
      "End time: 2025-09-22 03:30:36\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "\n",
      "Results for 5 concurrent requests with 15000 tokens:\n",
      "Average TTFT: 80.82s\n",
      "Average gen tokens/sec: 11.62\n",
      "Average total time: 93.22s\n",
      "Total concurrent time: 142.34s\n",
      "Valid requests: 5/5\n",
      "Results saved to: speed_tests/T2_x2/Qwen3-14B-INT8/15000_length_5_parallel.txt\n",
      "\n",
      "================================================================================\n",
      "Testing 5 concurrent requests with 20000 input tokens each\n",
      "================================================================================\n",
      "Waiting for all 5 threads to complete...\n",
      "**Огонь и лед**  \n",
      "**Хантер Эрин**  \n",
      "*Глава I (продолжение)*\n",
      "\n",
      "Огнегрив и Крутобок стояли в пещере Синей Звезды, не зная, что сказать. Задание было тяжелым, но они не могли отказаться — это был их шанс проявить себя как воины.\n",
      "\n",
      "— Мы не сможем найти их, еслиStart time: 2025-09-22 03:31:14\n",
      "End time: 2025-09-22 03:31:21\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "**Огонь и лед**  \n",
      "**Эрин Хантер**  \n",
      "**Глава I (продолжение)**\n",
      "\n",
      "— **Вам уже приходилось бывать на землях племени Ветра,** — напомнила предводительница. — **Вы знаете, что искать, и как к ним подойти.**  \n",
      "Огнегрив и Крутобок переглянулись. ИхStart time: 2025-09-22 03:31:58\n",
      "End time: 2025-09-22 03:32:05\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "**Огонь и лед — Эрин Хантер**  \n",
      "*Глава III (продолжение)*\n",
      "\n",
      "— **Вам уже приходилось бывать на землях племени Ветра**, — напомнила предводительница.  \n",
      "— **Так что вы знаете, где искать**, — добавил Коготь, его голос был низким и суровым, как всегда.  \n",
      "\n",
      "ОгнегStart time: 2025-09-22 03:32:43\n",
      "End time: 2025-09-22 03:32:50\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "**Конец главы III (продолжение):**\n",
      "\n",
      "— Мы не знаем, куда ушло племя Ветра, поэтому вам придется искать их по запаху — возможно, даже на враждебной территории.  \n",
      "Огнегрив и Крутобок обменялись взглядами. В их сердцах зашевелилась тревога. Они оба отлично помнили, как тяжелоStart time: 2025-09-22 03:33:30\n",
      "End time: 2025-09-22 03:33:38\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "**Огонь и лед**  \n",
      "**Хантер Эрин**\n",
      "\n",
      "---\n",
      "\n",
      "**Пролог**  \n",
      "Во время войны между кланами Сумрачное племя изгнало котов племени Ветра с их территории, что нарушило равновесие в лесу. Для восстановления справедливости и заведенного порядка Синяя Звезда дает Огнегриву и КрутStart time: 2025-09-22 03:34:15\n",
      "End time: 2025-09-22 03:34:22\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "\n",
      "Results for 5 concurrent requests with 20000 tokens:\n",
      "Average TTFT: 125.07s\n",
      "Average gen tokens/sec: 13.98\n",
      "Average total time: 132.24s\n",
      "Total concurrent time: 224.46s\n",
      "Valid requests: 5/5\n",
      "Results saved to: speed_tests/T2_x2/Qwen3-14B-INT8/20000_length_5_parallel.txt\n",
      "\n",
      "================================================================================\n",
      "Testing 5 concurrent requests with 25000 input tokens each\n",
      "================================================================================\n",
      "Waiting for all 5 threads to complete...\n",
      "**Огонь и лед**  \n",
      "**Хантер Эрин**  \n",
      "**Глава IV (продолжение)**\n",
      "\n",
      "Огнегрив тщательно принюхался и сделал несколько шагов вперед, следуя за тонким шлейфом запаха, который вился среди остатков разрушенного лагеря. Он чувствовал, как его сердце бьется быстрее — вStart time: 2025-09-22 03:35:14\n",
      "End time: 2025-09-22 03:35:21\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "**Огонь и лед**  \n",
      "*Эрин Хантер*  \n",
      "\n",
      "---\n",
      "\n",
      "### **Пролог**  \n",
      "Во время войны между кланами **Сумрачное племя** изгнало котов племени **Ветра** с их территории, что нарушило равновесие в лесу. Для восстановления справедливости и заведенного порядка **Синяя Звезда** дает **ОStart time: 2025-09-22 03:36:18\n",
      "End time: 2025-09-22 03:36:26\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "**Огонь и лед**  \n",
      "**Эрин Хантер**  \n",
      "**Глава IV (продолжение)**\n",
      "\n",
      "Огнегрив тщательно принюхался и сделал несколько шагов вперед, следуя за запахом племени Ветра, который был тонким, но явным. Он ощущал, как он уводил их глубже в пустыню, откуда исStart time: 2025-09-22 03:37:20\n",
      "End time: 2025-09-22 03:37:27\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "**Огонь и лед**  \n",
      "*Эрин Хантер*  \n",
      "\n",
      "---\n",
      "\n",
      "### Глава IV (продолжение)\n",
      "\n",
      "Огнегрив тщательно принюхался и сделал несколько шагов вперед, следуя за тонким и слабым запахом, исходившим от племени Ветра. Он понимал, что это запах, оставленный котами, которые покинулиStart time: 2025-09-22 03:38:22\n",
      "End time: 2025-09-22 03:38:30\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "**Огонь и лед**  \n",
      "**Эрин Хантер**  \n",
      "\n",
      "---\n",
      "\n",
      "### Глава IV (продолжение)\n",
      "\n",
      "Огнегрив тщательно принюхался и сделал несколько шагов вперед, следуя за тонким, но настойчивым ароматом племени Ветра. Запах был тонким, почти незаметным среди разрушений, но он не останавлиStart time: 2025-09-22 03:39:25\n",
      "End time: 2025-09-22 03:39:32\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "\n",
      "Results for 5 concurrent requests with 25000 tokens:\n",
      "Average TTFT: 174.14s\n",
      "Average gen tokens/sec: 13.27\n",
      "Average total time: 181.72s\n",
      "Total concurrent time: 307.62s\n",
      "Valid requests: 5/5\n",
      "Results saved to: speed_tests/T2_x2/Qwen3-14B-INT8/25000_length_5_parallel.txt\n",
      "\n",
      "================================================================================\n",
      "Testing 5 concurrent requests with 30000 input tokens each\n",
      "================================================================================\n",
      "Waiting for all 5 threads to complete...\n",
      "**Продолжение главы V:**\n",
      "\n",
      "Огнегрив беспокойно распушил свою рыжую шерсть и почувствовал под боком щекочущий кошачий холод — он не мог не заметить, что тоннель под землёй вибрировал от громкого рева, доносившегося сверху. Гремящая ТропаStart time: 2025-09-22 03:40:46\n",
      "End time: 2025-09-22 03:40:53\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "Продолжение главы V:\n",
      "\n",
      "Огнегрив беспокойно распушил свою рыжую шерсть и почувствовал под боком щекочущий коготь Крутобока, который тесно прижался к нему, стараясь укрыться от ревущего ветра, вырывающегося из-под Гремящей Тропы.\n",
      "\n",
      "— Это не просто нStart time: 2025-09-22 03:42:09\n",
      "End time: 2025-09-22 03:42:18\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n",
      "**Огонь и лед**  \n",
      "**Эрин Хантер**  \n",
      "**Глава V (продолжение)**  \n",
      "\n",
      "Огнегрив остановился, понюхал сырой воздух и не учуял ничего, кроме испарений Гремящей Тропы. Над головой рокотало так, что стены содрогались. Огнегрив почувствовал, что у него дрожатStart time: 2025-09-22 03:43:33\n",
      "End time: 2025-09-22 03:43:40\n",
      "Tokens generated: 100\n",
      "Generation speed formula: Tokens/sec = Total tokens / Total time\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def measure_vllm_response(file_path, vllm_url=\"http://localhost:8000/v1/chat/completions\", \n",
    "                         max_input_tokens=None, max_output_tokens=1024, max_generation_time=7.0, \n",
    "                         print_stream=False, benchmark_mode=False):\n",
    "    \"\"\"\n",
    "    Send file content to vLLM chat endpoint and measure response metrics with streaming\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the input file\n",
    "        vllm_url: vLLM endpoint URL\n",
    "        max_input_tokens: Maximum tokens for input (for truncation), None for no limit\n",
    "        max_output_tokens: Maximum tokens for output response\n",
    "        max_generation_time: Maximum time in seconds for generation after prefill (default: 7.0)\n",
    "        print_stream: Whether to print streaming content (default: False for benchmarking)\n",
    "        benchmark_mode: If True, optimize for precise TTFT measurement\n",
    "    \"\"\"\n",
    "    # Read the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Truncate content if max_input_tokens is specified\n",
    "    if max_input_tokens is not None:\n",
    "        tokens = tokenizer.encode(content)\n",
    "        if len(tokens) > max_input_tokens:\n",
    "            truncated_tokens = tokens[:max_input_tokens]\n",
    "            content = tokenizer.decode(truncated_tokens)\n",
    "            if not benchmark_mode:\n",
    "                print(f\"Content truncated from {len(tokens)} to {max_input_tokens} tokens\")\n",
    "    \n",
    "    # Get actual input token count\n",
    "    input_tokens = len(tokenizer.encode(content))\n",
    "    \n",
    "    # Prepare chat request with streaming\n",
    "    payload = {\n",
    "        \"model\": \"qwen3\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": content}\n",
    "        ],\n",
    "        \"max_tokens\": max_output_tokens,\n",
    "        \"temperature\": 0.7,\n",
    "        \"stream\": True,\n",
    "        \"stream_options\": {\"include_usage\": True},  # Request usage info in stream\n",
    "        \"chat_template_kwargs\": {\n",
    "                \"enable_thinking\": False\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Accept\": \"text/event-stream\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "    }\n",
    "    \n",
    "    # Use session for better connection management\n",
    "    session = requests.Session()\n",
    "    \n",
    "    # Start timing\n",
    "    start_time = time.time()\n",
    "    ttft = None\n",
    "    generation_start_time = None\n",
    "    generation_stopped_early = False\n",
    "    \n",
    "    # Send request to vLLM with streaming\n",
    "    response = session.post(vllm_url, json=payload, headers=headers, stream=True)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        session.close()\n",
    "        raise Exception(f\"Request failed with status {response.status_code}: {response.text}\")\n",
    "    \n",
    "    # Process streaming response\n",
    "    full_response = \"\"\n",
    "    output_tokens = 0\n",
    "    actual_input_tokens = None\n",
    "    actual_output_tokens = None\n",
    "    \n",
    "    if print_stream and not benchmark_mode:\n",
    "        print(\"Response streaming:\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Use minimal buffering for faster first token detection\n",
    "        for line in response.iter_lines(chunk_size=1, decode_unicode=True):\n",
    "            if not line:\n",
    "                continue\n",
    "                \n",
    "            if line.startswith('data: '):\n",
    "                data_str = line[6:]  # Remove 'data: ' prefix\n",
    "                if data_str.strip() == '[DONE]':\n",
    "                    break\n",
    "                \n",
    "                try:\n",
    "                    data = json.loads(data_str)\n",
    "                    \n",
    "                    # Check for usage information (comes in final event)\n",
    "                    if 'usage' in data:\n",
    "                        actual_input_tokens = data['usage']['prompt_tokens']\n",
    "                        actual_output_tokens = data['usage']['completion_tokens']\n",
    "                        if not benchmark_mode:\n",
    "                            print(f\"\\nUsage info received: {actual_input_tokens} input tokens, {actual_output_tokens} output tokens\")\n",
    "                    \n",
    "                    if 'choices' in data and len(data['choices']) > 0:\n",
    "                        choice = data['choices'][0]\n",
    "                        if 'delta' in choice and 'content' in choice['delta']:\n",
    "                            current_time = time.time()\n",
    "                            \n",
    "                            # Record TTFT (time to first token) - do this FIRST before any other processing\n",
    "                            if ttft is None:\n",
    "                                ttft = current_time - start_time\n",
    "                                generation_start_time = current_time\n",
    "                            \n",
    "                            content_chunk = choice['delta']['content']\n",
    "                            full_response += content_chunk\n",
    "                            \n",
    "                            # Print the streaming tokens\n",
    "                            print(content_chunk, end='', flush=True)\n",
    "                            \n",
    "                            # Check if generation time exceeds max_generation_time (only if not benchmark mode)\n",
    "                            if not benchmark_mode and generation_start_time is not None:\n",
    "                                generation_elapsed = current_time - generation_start_time\n",
    "                                if generation_elapsed > max_generation_time:\n",
    "                                    print(f\"\\nGeneration stopped early after {generation_elapsed:.2f} seconds (max: {max_generation_time}s)\")\n",
    "                                    generation_stopped_early = True\n",
    "                                    response.close()\n",
    "                                    break\n",
    "                            \n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "            \n",
    "            # Check timeout after each line as well (only if not benchmark mode)\n",
    "            if not benchmark_mode and generation_start_time is not None:\n",
    "                generation_elapsed = time.time() - generation_start_time\n",
    "                if generation_elapsed > max_generation_time:\n",
    "                    print(f\"\\nGeneration stopped early after {generation_elapsed:.2f} seconds (max: {max_generation_time}s)\")\n",
    "                    generation_stopped_early = True\n",
    "                    response.close()\n",
    "                    break\n",
    "    \n",
    "    except Exception as e:\n",
    "        # If there's any error during streaming, close the response\n",
    "        response.close()\n",
    "        session.close()\n",
    "        if not generation_stopped_early:\n",
    "            raise e\n",
    "    \n",
    "    # Clean up\n",
    "    response.close()\n",
    "    session.close()\n",
    "    \n",
    "    if print_stream and not benchmark_mode:\n",
    "        print()  # New line after streaming\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    \n",
    "    # If no TTFT was recorded (no tokens received), set it to total time\n",
    "    if ttft is None:\n",
    "        ttft = total_time\n",
    "    \n",
    "    # Use actual token counts from server if available, otherwise fall back to tokenizer estimate\n",
    "    if actual_input_tokens is not None and actual_output_tokens is not None and not generation_stopped_early:\n",
    "        input_tokens = actual_input_tokens\n",
    "        output_tokens = actual_output_tokens\n",
    "        if not benchmark_mode:\n",
    "            print(f\"Using server-reported token counts: {input_tokens} input, {output_tokens} output\")\n",
    "    else:\n",
    "        # Fallback: estimate output tokens using tokenizer\n",
    "        output_tokens = len(tokenizer.encode(full_response))\n",
    "        if not benchmark_mode:\n",
    "            print(f\"Using tokenizer estimates: {input_tokens} input, {output_tokens} output\")\n",
    "            if generation_stopped_early:\n",
    "                print(\"Note: Generation was stopped early due to time limit\")\n",
    "    \n",
    "    # Calculate generation speed using actual token counts\n",
    "    generation_time = max(total_time - ttft, 1e-9)\n",
    "    gen_tokens_per_sec = output_tokens / generation_time\n",
    "    \n",
    "    # Total tokens\n",
    "    total_tokens = input_tokens + output_tokens\n",
    "    \n",
    "    # Metrics dictionary\n",
    "    metrics = {\n",
    "        'ttft': ttft,\n",
    "        'gen_tokens_per_sec': gen_tokens_per_sec,\n",
    "        'total_tokens': total_tokens,\n",
    "        'total_time': total_time,\n",
    "        'input_tokens': input_tokens,\n",
    "        'output_tokens': output_tokens,\n",
    "        'generation_time': generation_time,\n",
    "        'generation_stopped_early': generation_stopped_early\n",
    "    }\n",
    "    \n",
    "    # Print additional information\n",
    "    # if not benchmark_mode:\n",
    "    start_time_formatted = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(generation_start_time))\n",
    "    end_time_formatted = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(end_time))\n",
    "    print(f\"Start time: {start_time_formatted}\")\n",
    "    print(f\"End time: {end_time_formatted}\")\n",
    "    print(f\"Tokens generated: {output_tokens}\")\n",
    "    print(f\"Generation speed formula: Tokens/sec = Total tokens / Total time\")\n",
    "\n",
    "    return full_response, metrics\n",
    "\n",
    "def save_and_print_metrics(response, metrics, output_file):\n",
    "    \"\"\"\n",
    "    Save response and metrics to file and print metrics\n",
    "    \"\"\"\n",
    "    # Print metrics\n",
    "    print(f\"TTFT: {metrics['ttft']:.2f} seconds\")\n",
    "    print(f\"Gen tokens/sec (post-TTFT): {metrics['gen_tokens_per_sec']:.2f}\")\n",
    "    # print(f\"E2E tokens/sec (incl. prefill): {metrics['e2e_tokens_per_sec']:.2f}\")\n",
    "    print(f\"Total tokens: {metrics['total_tokens']}\")\n",
    "    print(f\"Input tokens: {metrics['input_tokens']}\")\n",
    "    print(f\"Output tokens: {metrics['output_tokens']}\")\n",
    "    print(f\"Total time: {metrics['total_time']:.2f} seconds\")\n",
    "    print(f\"Generation time: {metrics['generation_time']:.2f} seconds\")\n",
    "    if metrics.get('generation_stopped_early', False):\n",
    "        print(\"Generation was stopped early due to time limit\")\n",
    "    \n",
    "    # Save to file\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        # Write metrics in the format similar to the examples\n",
    "        f.write(f\"ttft: {metrics['ttft']:.2f}\\n\")\n",
    "        f.write(f\"gen_tokens_per_second: {metrics['gen_tokens_per_sec']:.2f}\\n\")\n",
    "        # f.write(f\"e2e_tokens_per_second: {metrics['e2e_tokens_per_sec']:.2f}\\n\")\n",
    "        f.write(f\"total_tokens: {metrics['total_tokens']}\\n\")\n",
    "        f.write(f\"total_time: {metrics['total_time']:.2f}\\n\")\n",
    "        f.write(f\"input_tokens: {metrics['input_tokens']}\\n\")\n",
    "        f.write(f\"output_tokens: {metrics['output_tokens']}\\n\")\n",
    "        f.write(f\"generation_time: {metrics['generation_time']:.2f}\\n\")\n",
    "        if metrics.get('generation_stopped_early', False):\n",
    "            f.write(\"generation_stopped_early: true\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(response)\n",
    "\n",
    "file_path = \"tests/book.txt\"\n",
    "vllm_url = \"http://localhost:8000/v1/chat/completions\"\n",
    "max_output_tokens = 100\n",
    "\n",
    "import threading\n",
    "import time\n",
    "import os\n",
    "\n",
    "def run_concurrent_test(file_path, max_input_tokens, max_output_tokens, request_id):\n",
    "    \"\"\"Run a single request for concurrent testing\"\"\"\n",
    "    if not os.environ.get('BENCHMARK_QUIET'):\n",
    "        print(f\"Starting request {request_id}\")\n",
    "    start = time.time()\n",
    "    \n",
    "    try:\n",
    "        response, metrics = measure_vllm_response(\n",
    "            file_path=file_path,\n",
    "            max_input_tokens=max_input_tokens,\n",
    "            max_output_tokens=max_output_tokens,\n",
    "            print_stream=False,  # Disable streaming output for benchmarks\n",
    "            benchmark_mode=True   # Enable benchmark optimizations\n",
    "        )\n",
    "            \n",
    "        end = time.time()\n",
    "        if not os.environ.get('BENCHMARK_QUIET'):\n",
    "            print(f\"Request {request_id} completed in {end - start:.2f}s\")\n",
    "        return metrics\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Request {request_id} failed: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"Testing different input token sizes with various concurrent requests:\")\n",
    "\n",
    "input_token_sizes = [1000, 5000, 10000, 15000, 20000, 25000, 30000]\n",
    "# input_token_sizes = [15000]\n",
    "concurrent_counts = [2, 5]\n",
    "\n",
    "# Set environment variable to reduce noise during benchmarking\n",
    "os.environ['BENCHMARK_QUIET'] = '1'\n",
    "\n",
    "for concurrent_count in concurrent_counts:\n",
    "    for token_size in input_token_sizes:\n",
    "        print(f\"\\n\" + \"=\"*80)\n",
    "        print(f\"Testing {concurrent_count} concurrent requests with {token_size} input tokens each\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        threads = []\n",
    "        all_metrics = []\n",
    "        \n",
    "        # Start all threads\n",
    "        concurrent_start_time = time.time()\n",
    "        for i in range(concurrent_count):\n",
    "            thread = threading.Thread(\n",
    "                target=lambda i=i: all_metrics.append(\n",
    "                    run_concurrent_test(file_path, token_size, max_output_tokens, i+1)\n",
    "                )\n",
    "            )\n",
    "            threads.append(thread)\n",
    "            thread.start()\n",
    "            time.sleep(0.1)  # Small delay to avoid overwhelming the server\n",
    "        \n",
    "        # Wait for all threads to complete\n",
    "        print(f\"Waiting for all {concurrent_count} threads to complete...\")\n",
    "        for i, thread in enumerate(threads):\n",
    "            thread.join()\n",
    "            if not os.environ.get('BENCHMARK_QUIET'):\n",
    "                print(f\"Thread {i+1} joined\")\n",
    "        \n",
    "        concurrent_end_time = time.time()\n",
    "        total_concurrent_time = concurrent_end_time - concurrent_start_time\n",
    "        \n",
    "        # Filter out None results (failed requests)\n",
    "        valid_metrics = [m for m in all_metrics if m is not None]\n",
    "        valid_requests = len(valid_metrics)\n",
    "        \n",
    "        if valid_requests > 0:\n",
    "            # Calculate aggregate metrics\n",
    "            avg_ttft = sum(m['ttft'] for m in valid_metrics) / valid_requests\n",
    "            avg_gen_tokens_per_sec = sum(m['gen_tokens_per_sec'] for m in valid_metrics) / valid_requests\n",
    "            avg_total_tokens = sum(m['total_tokens'] for m in valid_metrics) / valid_requests\n",
    "            avg_total_time = sum(m['total_time'] for m in valid_metrics) / valid_requests\n",
    "            avg_input_tokens = sum(m['input_tokens'] for m in valid_metrics) / valid_requests\n",
    "            avg_output_tokens = sum(m['output_tokens'] for m in valid_metrics) / valid_requests\n",
    "            \n",
    "            # Create output filename\n",
    "            # Get model name from API\n",
    "            response = requests.get(\"http://localhost:8000/v1/models\")\n",
    "            model_name = response.json()['data'][0]['root'].split('/')[-1]\n",
    "            \n",
    "            output_filename = f\"speed_tests/T2_x2/{model_name}/{token_size}_length_{concurrent_count}_parallel.txt\"\n",
    "            os.makedirs(os.path.dirname(output_filename), exist_ok=True)\n",
    "            # Save results to file\n",
    "            with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "                # Write aggregate metrics\n",
    "                f.write(f\"ttft: {avg_ttft:.2f}\\n\")\n",
    "                f.write(f\"gen_tokens_per_second: {avg_gen_tokens_per_sec:.2f}\\n\")\n",
    "                f.write(f\"total_tokens: {avg_total_tokens:.0f}\\n\")\n",
    "                f.write(f\"total_time: {avg_total_time:.2f}\\n\")\n",
    "                f.write(f\"input_tokens: {avg_input_tokens:.0f}\\n\")\n",
    "                f.write(f\"output_tokens: {avg_output_tokens:.0f}\\n\")\n",
    "                f.write(f\"concurrent_requests: {concurrent_count}\\n\")\n",
    "                f.write(f\"valid_requests: {valid_requests}\\n\")\n",
    "                f.write(f\"total_concurrent_time: {total_concurrent_time:.2f}\\n\")\n",
    "                f.write(f\"\\nAverage metrics for {valid_requests}/{concurrent_count} concurrent requests of {token_size} tokens each\\n\\n\")\n",
    "                \n",
    "                # Write individual request metrics\n",
    "                f.write(\"Individual request metrics:\\n\\n\")\n",
    "                for i, metrics in enumerate(valid_metrics):\n",
    "                    f.write(f\"Request {i+1}:\\n\")\n",
    "                    f.write(f\"  ttft: {metrics['ttft']:.2f}\\n\")\n",
    "                    f.write(f\"  gen_tokens_per_second: {metrics['gen_tokens_per_sec']:.2f}\\n\")\n",
    "                    f.write(f\"  total_tokens: {metrics['total_tokens']}\\n\")\n",
    "                    f.write(f\"  total_time: {metrics['total_time']:.2f}\\n\")\n",
    "                    f.write(f\"  input_tokens: {metrics['input_tokens']}\\n\")\n",
    "                    f.write(f\"  output_tokens: {metrics['output_tokens']}\\n\")\n",
    "                    f.write(f\"\\n\")\n",
    "            \n",
    "            print(f\"\\nResults for {concurrent_count} concurrent requests with {token_size} tokens:\")\n",
    "            print(f\"Average TTFT: {avg_ttft:.2f}s\")\n",
    "            print(f\"Average gen tokens/sec: {avg_gen_tokens_per_sec:.2f}\")\n",
    "            print(f\"Average total time: {avg_total_time:.2f}s\")\n",
    "            print(f\"Total concurrent time: {total_concurrent_time:.2f}s\")\n",
    "            print(f\"Valid requests: {valid_requests}/{concurrent_count}\")\n",
    "            print(f\"Results saved to: {output_filename}\")\n",
    "        else:\n",
    "            print(f\"All requests failed for {concurrent_count} concurrent requests with {token_size} tokens\")\n",
    "        \n",
    "        # Brief pause between tests\n",
    "        time.sleep(2)\n",
    "\n",
    "# Clean up environment variable\n",
    "if 'BENCHMARK_QUIET' in os.environ:\n",
    "    del os.environ['BENCHMARK_QUIET']\n",
    "\n",
    "print(\"\\nAll tests completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae75fda7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9660eb2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
