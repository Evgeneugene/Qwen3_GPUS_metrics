{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3a86001",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'gpu_setup'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m/tmp/ipykernel_17555/3069876427.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    149\u001b[39m         per_request_rows.append({**base_meta, **r})\n\u001b[32m    150\u001b[39m \n\u001b[32m    151\u001b[39m \u001b[38;5;66;03m# ---------- Выгрузка CSV ----------\u001b[39;00m\n\u001b[32m    152\u001b[39m df_files = pd.DataFrame(file_rows)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m df_files.sort_values([\u001b[33m\"gpu_setup\"\u001b[39m, \u001b[33m\"model\"\u001b[39m, \u001b[33m\"input_len\"\u001b[39m, \u001b[33m\"parallel\"\u001b[39m], inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    154\u001b[39m out_csv = OUT_DIR / \u001b[33m\"speed_summary.csv\"\u001b[39m\n\u001b[32m    155\u001b[39m df_files.to_csv(out_csv, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    156\u001b[39m \n",
      "\u001b[32m~/llms/Qwen3_GPUS_metrics/.venv/lib/python3.12/site-packages/pandas/core/frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[39m\n\u001b[32m   7175\u001b[39m                 f\"Length of ascending ({len(ascending)})\"  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m   7176\u001b[39m                 f\" != length of by ({len(by)})\"\n\u001b[32m   7177\u001b[39m             )\n\u001b[32m   7178\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m len(by) > \u001b[32m1\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7179\u001b[39m             keys = [self._get_label_or_level_values(x, axis=axis) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;28;01min\u001b[39;00m by]\n\u001b[32m   7180\u001b[39m \n\u001b[32m   7181\u001b[39m             \u001b[38;5;66;03m# need to rewrap columns in Series to apply key function\u001b[39;00m\n\u001b[32m   7182\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32m~/llms/Qwen3_GPUS_metrics/.venv/lib/python3.12/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1907\u001b[39m             values = self.xs(key, axis=other_axes[\u001b[32m0\u001b[39m])._values\n\u001b[32m   1908\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m self._is_level_reference(key, axis=axis):\n\u001b[32m   1909\u001b[39m             values = self.axes[axis].get_level_values(key)._values\n\u001b[32m   1910\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1911\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m KeyError(key)\n\u001b[32m   1912\u001b[39m \n\u001b[32m   1913\u001b[39m         \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[32m   1914\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m values.ndim > \u001b[32m1\u001b[39m:\n",
      "\u001b[31mKeyError\u001b[39m: 'gpu_setup'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Сбор сравнительных таблиц по результатам из speed_tests/.\n",
    "- Парсит файлы формата:\n",
    "    root/speed_tests/<GPU_SETUP>/<MODEL>/<INPUTLEN>_length_<PARALLEL>_parallel.txt\n",
    "- Извлекает \"Average metrics ...\" и блоки \"Individual request metrics\".\n",
    "- Складывает результаты в:\n",
    "    - speed_summary.csv                    — построчная таблица по каждому файлу\n",
    "    - speed_summary_per_request.csv        — таблица по каждому индивидуальному запросу\n",
    "    - speed_summary.md                     — удобная Markdown-версия результата\n",
    "    - pivots/                              — несколько сводных CSV\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from statistics import median\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "root_dir = \"/root/llms/Qwen3_GPUS_metrics\"\n",
    "ROOT = Path(root_dir).resolve().parents[1]  # корень репозитория\n",
    "SPEED_TESTS_DIR = ROOT / \"speed_tests\"\n",
    "OUT_DIR = ROOT\n",
    "PIVOT_DIR = OUT_DIR / \"pivots\"\n",
    "PIVOT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# ---------- Регексы для парсинга содержимого ----------\n",
    "# Общие средние метрики\n",
    "AVG_LINE_PATTERNS = {\n",
    "    \"ttft\": re.compile(r\"\\bttft:\\s*([0-9]+(?:\\.[0-9]+)?)\", re.I),\n",
    "    \"tokens_per_second\": re.compile(r\"\\btokens_per_second:\\s*([0-9]+(?:\\.[0-9]+)?)\", re.I),\n",
    "    \"total_tokens\": re.compile(r\"\\btotal_tokens:\\s*([0-9]+)\", re.I),\n",
    "    \"total_time\": re.compile(r\"\\btotal_time:\\s*([0-9]+(?:\\.[0-9]+)?)\", re.I),\n",
    "    \"input_tokens\": re.compile(r\"\\binput_tokens:\\s*([0-9]+)\", re.I),\n",
    "    \"output_tokens\": re.compile(r\"\\boutput_tokens:\\s*([0-9]+)\", re.I),\n",
    "    \"concurrent_requests\": re.compile(r\"\\bconcurrent_requests:\\s*([0-9]+)\", re.I),\n",
    "    \"valid_requests\": re.compile(r\"\\bvalid_requests:\\s*([0-9]+)\", re.I),\n",
    "    \"total_concurrent_time\": re.compile(r\"\\btotal_concurrent_time:\\s*([0-9]+(?:\\.[0-9]+)?)\", re.I),\n",
    "}\n",
    "\n",
    "# Шапка про средние для N/N\n",
    "AVG_BLOCK_HEADER = re.compile(\n",
    "    r\"Average metrics for\\s+(\\d+)\\s*/\\s*(\\d+)\\s*concurrent requests.*\", re.I\n",
    ")\n",
    "\n",
    "# Индивидуальные блоки:\n",
    "REQUEST_BLOCK_RE = re.compile(\n",
    "    r\"Request\\s+(\\d+):\\s*(.*?)\\n(?=Request\\s+\\d+:|$)\", re.I | re.S\n",
    ")\n",
    "REQ_FIELD_RE = {\n",
    "    \"ttft\": re.compile(r\"\\bttft:\\s*([0-9]+(?:\\.[0-9]+)?)\", re.I),\n",
    "    \"tokens_per_second\": re.compile(r\"\\btokens_per_second:\\s*([0-9]+(?:\\.[0-9]+)?)\", re.I),\n",
    "    \"total_tokens\": re.compile(r\"\\btotal_tokens:\\s*([0-9]+)\", re.I),\n",
    "    \"total_time\": re.compile(r\"\\btotal_time:\\s*([0-9]+(?:\\.[0-9]+)?)\", re.I),\n",
    "    \"input_tokens\": re.compile(r\"\\binput_tokens:\\s*([0-9]+)\", re.I),\n",
    "    \"output_tokens\": re.compile(r\"\\boutput_tokens:\\s*([0-9]+)\", re.I),\n",
    "}\n",
    "\n",
    "# ---------- Вспомогательные функции ----------\n",
    "def parse_path_meta(file_path: Path):\n",
    "    \"\"\"\n",
    "    Извлекает GPU setup, модель, длину, параллелизм из пути.\n",
    "    Пример: speed_tests/A2_x2/Qwen3-8B/5000_length_5_parallel.txt\n",
    "    \"\"\"\n",
    "    gpu_setup = file_path.parts[-3]\n",
    "    model = file_path.parts[-2]\n",
    "    basename = file_path.stem  # '5000_length_5_parallel'\n",
    "    m = re.match(r\"(\\d+)_length_(\\d+)_parallel\", basename)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Не удалось распарсить имя файла: {basename}\")\n",
    "    input_len = int(m.group(1))\n",
    "    parallel = int(m.group(2))\n",
    "    return gpu_setup, model, input_len, parallel\n",
    "\n",
    "def parse_averages(text: str):\n",
    "    data = {}\n",
    "    # Пробуем вытащить \"Average metrics for X/Y concurrent requests\"\n",
    "    m = AVG_BLOCK_HEADER.search(text)\n",
    "    if m:\n",
    "        data[\"avg_requests_ok\"] = int(m.group(1))\n",
    "        data[\"avg_requests_total\"] = int(m.group(2))\n",
    "    else:\n",
    "        data[\"avg_requests_ok\"] = None\n",
    "        data[\"avg_requests_total\"] = None\n",
    "\n",
    "    for k, rx in AVG_LINE_PATTERNS.items():\n",
    "        mm = rx.search(text)\n",
    "        data[k] = float(mm.group(1)) if mm and '.' in mm.group(1) else (int(mm.group(1)) if mm else None)\n",
    "    return data\n",
    "\n",
    "def parse_per_request(text: str):\n",
    "    per_rows = []\n",
    "    for m in REQUEST_BLOCK_RE.finditer(text):\n",
    "        req_id = int(m.group(1))\n",
    "        block = m.group(2)\n",
    "        row = {\"req_id\": req_id}\n",
    "        for k, rx in REQ_FIELD_RE.items():\n",
    "            mm = rx.search(block)\n",
    "            row[k] = float(mm.group(1)) if mm and '.' in mm.group(1) else (int(mm.group(1)) if mm else None)\n",
    "        per_rows.append(row)\n",
    "    return sorted(per_rows, key=lambda r: r[\"req_id\"])\n",
    "\n",
    "# ---------- Основной проход по файлам ----------\n",
    "file_rows = []\n",
    "per_request_rows = []\n",
    "\n",
    "for txt in SPEED_TESTS_DIR.rglob(\"*.txt\"):\n",
    "    try:\n",
    "        gpu_setup, model, input_len, parallel = parse_path_meta(txt)\n",
    "    except Exception:\n",
    "        # пропускаем несоответствующие маске файлы\n",
    "        continue\n",
    "\n",
    "    content = txt.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    avg = parse_averages(content)\n",
    "    req_rows = parse_per_request(content)\n",
    "\n",
    "    base_meta = {\n",
    "        \"gpu_setup\": gpu_setup,\n",
    "        \"model\": model,\n",
    "        \"input_len\": input_len,\n",
    "        \"parallel\": parallel,\n",
    "        \"source_file\": str(txt.relative_to(ROOT)),\n",
    "    }\n",
    "\n",
    "    # Строка со средними метриками\n",
    "    row = {**base_meta, **avg}\n",
    "    # Доп. удобные поля\n",
    "    if avg.get(\"total_tokens\") and avg.get(\"total_time\"):\n",
    "        row[\"avg_throughput_tokens_s\"] = float(avg[\"total_tokens\"]) / float(avg[\"total_time\"]) if float(avg[\"total_time\"]) > 0 else None\n",
    "    else:\n",
    "        row[\"avg_throughput_tokens_s\"] = None\n",
    "\n",
    "    # Медианы по индивидуальным запросам (если есть)\n",
    "    if req_rows:\n",
    "        for metric in (\"ttft\", \"tokens_per_second\", \"total_time\", \"input_tokens\", \"output_tokens\", \"total_tokens\"):\n",
    "            vals = [r[metric] for r in req_rows if r.get(metric) is not None]\n",
    "            row[f\"median_{metric}\"] = float(median(vals)) if vals else None\n",
    "\n",
    "    file_rows.append(row)\n",
    "\n",
    "    # Сохраняем по-запросно\n",
    "    for r in req_rows:\n",
    "        per_request_rows.append({**base_meta, **r})\n",
    "\n",
    "# ---------- Выгрузка CSV ----------\n",
    "df_files = pd.DataFrame(file_rows)\n",
    "df_files.sort_values([\"gpu_setup\", \"model\", \"input_len\", \"parallel\"], inplace=True)\n",
    "out_csv = OUT_DIR / \"speed_summary.csv\"\n",
    "df_files.to_csv(out_csv, index=False)\n",
    "\n",
    "df_reqs = pd.DataFrame(per_request_rows)\n",
    "if not df_reqs.empty:\n",
    "    df_reqs.sort_values([\"gpu_setup\", \"model\", \"input_len\", \"parallel\", \"req_id\"], inplace=True)\n",
    "    out_csv_reqs = OUT_DIR / \"speed_summary_per_request.csv\"\n",
    "    df_reqs.to_csv(out_csv_reqs, index=False)\n",
    "\n",
    "# ---------- Пара готовых сводных таблиц (pivots) ----------\n",
    "if not df_files.empty:\n",
    "    # 1) Средний tokens_per_second по моделям и параллельности\n",
    "    p1 = pd.pivot_table(\n",
    "        df_files,\n",
    "        index=[\"gpu_setup\", \"model\"],\n",
    "        columns=\"parallel\",\n",
    "        values=\"tokens_per_second\",\n",
    "        aggfunc=\"mean\",\n",
    "    )\n",
    "    p1.to_csv(PIVOT_DIR / \"pivot_tokens_per_second_by_parallel.csv\")\n",
    "\n",
    "    # 2) Средний ttft по длине входа (чем короче колонок — тем лучше)\n",
    "    p2 = pd.pivot_table(\n",
    "        df_files,\n",
    "        index=[\"gpu_setup\", \"model\"],\n",
    "        columns=\"input_len\",\n",
    "        values=\"ttft\",\n",
    "        aggfunc=\"mean\",\n",
    "    )\n",
    "    p2.to_csv(PIVOT_DIR / \"pivot_ttft_by_inputlen.csv\")\n",
    "\n",
    "    # 3) Итоговый скользящий показатель throughput (avg_throughput_tokens_s)\n",
    "    p3 = pd.pivot_table(\n",
    "        df_files,\n",
    "        index=[\"gpu_setup\", \"model\"],\n",
    "        columns=\"parallel\",\n",
    "        values=\"avg_throughput_tokens_s\",\n",
    "        aggfunc=\"mean\",\n",
    "    )\n",
    "    p3.to_csv(PIVOT_DIR / \"pivot_avg_throughput_by_parallel.csv\")\n",
    "\n",
    "# ---------- Markdown-версия основной таблицы ----------\n",
    "md_path = OUT_DIR / \"speed_summary.md\"\n",
    "with open(md_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"# Speed Tests — Сводная таблица\\n\\n\")\n",
    "    if df_files.empty:\n",
    "        f.write(\"_Данные не найдены в папке `speed_tests/`._\\n\")\n",
    "    else:\n",
    "        # Ограничим количество колонок для читабельности\n",
    "        cols_show = [\n",
    "            \"gpu_setup\", \"model\", \"input_len\", \"parallel\",\n",
    "            \"ttft\", \"tokens_per_second\", \"total_time\",\n",
    "            \"input_tokens\", \"output_tokens\", \"total_tokens\",\n",
    "            \"avg_requests_ok\", \"avg_requests_total\",\n",
    "            \"avg_throughput_tokens_s\",\n",
    "            \"median_ttft\", \"median_tokens_per_second\", \"median_total_time\"\n",
    "        ]\n",
    "        cols_show = [c for c in cols_show if c in df_files.columns]\n",
    "        f.write(df_files[cols_show].to_markdown(index=False))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(f\"OK: {out_csv.name} создан.\")\n",
    "if not df_reqs.empty:\n",
    "    print(f\"OK: {out_csv_reqs.name} создан.\")\n",
    "print(f\"OK: Markdown: {md_path.name}\")\n",
    "print(f\"Сводные таблицы в: {PIVOT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c7e5be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
